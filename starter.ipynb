{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcalz23/logo_detection_w281/blob/main/starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "ftral3NsJS84",
        "outputId": "c088676a-864c-42f3-d411-ecf6dcfd95f0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c660fb3c1461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Drive to Access Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   metadata_server_addr = _os.environ[\n\u001b[0;32m--> 132\u001b[0;31m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[0m\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     _message.blocking_request(\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TBE_EPHEM_CREDS_ADDR'"
          ]
        }
      ],
      "source": [
        "# Mount Drive to Access Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"jcalz23\"\n",
        "!git config --global user.email \"j.calzaretta.ai@gmail.com\""
      ],
      "metadata": {
        "id": "qa1d3EKupWWZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/W281/assignment-5-jcalz23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a69Z7W8spwwY",
        "outputId": "a65ea0a7-c6ca-4e23-a457-5c5587044a4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assignment-5-jcalz23'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. IMPORTS & PATHS"
      ],
      "metadata": {
        "id": "F1maouX6LhSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(f\"tf version: {tf.__version__}\")\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Define paths\n",
        "base_dir = '/content/drive/MyDrive/logo_detection/'\n",
        "image_dir = base_dir + 'data/images/'\n",
        "os.chdir(base_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "9heDsbKLJjLc",
        "outputId": "08d4cf9f-6300-4211-d300-b3a4fdaf84fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf version: 2.8.0\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d37bf6f5cc71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/logo_detection/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data/images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/logo_detection/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. EDA"
      ],
      "metadata": {
        "id": "Wf4Gofw-MuoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load example image\n",
        "adidas_dir = image_dir + 'adidas/'\n",
        "adidas_img = plt.imread(adidas_dir + os.listdir(adidas_dir)[1])\n",
        "adidas_img2 = plt.imread(adidas_dir + os.listdir(adidas_dir)[4])\n",
        "print(f\"Image 1 is size: {adidas_img.shape}\")\n",
        "print(f\"Image 2 is size: {adidas_img2.shape}\")\n",
        "print(\"Notice different sizes ^^^\")\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax[0].imshow(adidas_img)\n",
        "ax[1].imshow(adidas_img2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p3P8VhqXKYPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate classes\n",
        "logo_list = os.listdir(image_dir)\n",
        "print(f\"There are {len(logo_list)}\")\n",
        "\n",
        "# Plot number of examples per class\n",
        "ex_counts = []\n",
        "for logo in logo_list:\n",
        "  count = len(os.listdir(image_dir + logo))\n",
        "  ex_counts.append(count)\n",
        "\n",
        "# make df\n",
        "logo_counts = pd.DataFrame({'brand': logo_list, 'count': ex_counts})\n",
        "logo_counts.sort_values('count', ascending=False, inplace=True)\n",
        "\n",
        "# visualize\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "sns.barplot(data=logo_counts, x=logo_list,\n",
        "            y=ex_counts)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K_oS_L3FL5An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create Train, Test Splits"
      ],
      "metadata": {
        "id": "xXcr0uZAQof3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create file dataframe\n",
        "labels = []\n",
        "files = []\n",
        "paths = []\n",
        "\n",
        "for logo in logo_list:\n",
        "  imgs = os.listdir(image_dir + logo)\n",
        "  for img in imgs:\n",
        "    files.append(img)\n",
        "    labels.append(logo)\n",
        "    paths.append(image_dir + logo + '/' + img)\n",
        "\n",
        "img_df = pd.DataFrame({'label': labels, 'file': files, 'path': paths})\n",
        "img_df.head()"
      ],
      "metadata": {
        "id": "zDKEfA-IQu0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly split df into train, test\n",
        "test_size = .3\n",
        "df_train, df_test, _, _ = train_test_split(img_df, img_df, \n",
        "                                           test_size=test_size, random_state=42)"
      ],
      "metadata": {
        "id": "pbfCryvpSx7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Modeling (Simple CNN Example)"
      ],
      "metadata": {
        "id": "5U4w6X35TM7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data loading params\n",
        "img_x = 64 #arbitrary for now\n",
        "img_y = 64\n",
        "batch_size = 32\n",
        "\n",
        "# Batch image augmentation\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale = 1.0/255, \n",
        "    shear_range = 0.2, \n",
        "    zoom_range = 0.2, \n",
        "    rotation_range=20,\n",
        "    horizontal_flip = True)\n",
        "train_generator = train_gen.flow_from_dataframe(\n",
        "    dataframe=df_train,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size = (img_x, img_y),\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "# Just rescale test, no augmentation\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=df_test,\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    target_size = (img_x, img_y),\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "vVQsp2yYTFHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### BUILD MODEL #### \n",
        "def build_simple_cnn(input_shape, batch_size, kernel_size, filters, pool_size, dropout, num_labels):\n",
        "    inputs = Input(shape=(input_shape))\n",
        "    \n",
        "    # Conv + Pool #1\n",
        "    conv1 = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(inputs)\n",
        "    maxp1 = MaxPooling2D(pool_size)(conv1)\n",
        "    drop1 = Dropout(dropout)(maxp1)\n",
        "    \n",
        "    # Conv + Pool #2\n",
        "    conv2 = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(drop1)\n",
        "    maxp2 = MaxPooling2D(pool_size)(conv2)\n",
        "    drop2 = Dropout(dropout)(maxp2)\n",
        "    \n",
        "    # Flatten + Dropoout\n",
        "    flat = Flatten()(drop2)\n",
        "    drop4 = Dropout(dropout)(flat)\n",
        "    \n",
        "    # Fully Connected\n",
        "    outputs = Dense(num_labels, activation = 'softmax')(drop4)\n",
        "    \n",
        "    # Build\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "FA7UVdY8Tnq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model params\n",
        "kernel_size = 7\n",
        "pool_size=(2, 2)\n",
        "filters = 8\n",
        "dropout = 0.3\n",
        "input_shape = (img_x, img_y, 3)\n",
        "num_labels = len(logo_list)\n",
        "\n",
        "# Training params\n",
        "epochs = 1\n",
        "\n",
        "model = build_simple_cnn(input_shape, batch_size, kernel_size, \n",
        "                         filters, pool_size, dropout, num_labels)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HN8K3bDaT5Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch = train_generator.samples // batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = test_generator,\n",
        "                    validation_steps = test_generator.samples // batch_size)"
      ],
      "metadata": {
        "id": "aQVV9j0hUPc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./model_objects/simple_cnn_test')"
      ],
      "metadata": {
        "id": "e60wxnu5r7uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluate Performance"
      ],
      "metadata": {
        "id": "03F6CCu2WNZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(test_generator)"
      ],
      "metadata": {
        "id": "aSvr1WaDWRBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get classification metrics"
      ],
      "metadata": {
        "id": "dhYoCs5VUdvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate difficult classes"
      ],
      "metadata": {
        "id": "JV8CBzmBWM2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZyE4UBMZWW6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}